{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting English tense from context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I. <a href=#I>Preliminary steps</a>\n",
    "##### II. <a href=#II>Prepare the data</a>\n",
    "##### III. <a href=#III>Feed-forward neural network model</a>\n",
    "##### IV. <a href=#IV>Long short-term memory model</a>\n",
    "##### V. <a href=#V>Naive discriminative learning model</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Preliminary steps <a ID=\"I\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries and set up the working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Import necessary packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Dense\n",
    "from keras.optimizers import Adam, Nadam, RMSprop, SGD\n",
    "from keras.activations import relu, elu\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras import metrics\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "\n",
    "### Set working directory\n",
    "TOP = '/media/adnane/HDD drive/Adnane/PostDoc_ooominds/Programming/Deep_text_modelling_package_repo/'\n",
    "#TOP = '/media/Deep_text_modelling_package_repo/'\n",
    "WD = TOP + 'package'\n",
    "os.chdir(WD)\n",
    "\n",
    "### Import local packages\n",
    "import deep_text_modelling.preprocessing as pr\n",
    "import deep_text_modelling.modelling as md\n",
    "import deep_text_modelling.evaluation as ev\n",
    "\n",
    "# Display option for dataframes and matplotlib\n",
    "pd.set_option('display.max_colwidth', 100) # Max width of columns when dispalying datasets\n",
    "PREVIOUS_MAX_ROWS = pd.options.display.max_rows\n",
    "pd.options.display.max_rows = 20\n",
    "warnings.filterwarnings('ignore') # Hide warnings\n",
    "warnings.simplefilter('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'deep_text_modelling.evaluation' from '/media/adnane/HDD drive/Adnane/PostDoc_ooominds/Programming/Deep_text_modelling_package_repo/package/deep_text_modelling/evaluation.py'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imp\n",
    "imp.reload(pr)\n",
    "imp.reload(md)\n",
    "imp.reload(ev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TENSES_FULL_CSV = TOP + \"illustrative_examples/tenses/Data/Tenses_full.csv\"\n",
    "TENSES_TRAIN_CSV = TOP + \"illustrative_examples/tenses/Data/Tenses_train.csv\"\n",
    "TENSES_VALID_CSV = TOP + \"illustrative_examples/tenses/Data/Tenses_valid.csv\"\n",
    "TENSES_TEST_CSV = TOP + \"illustrative_examples/tenses/Data/Tenses_test.csv\"\n",
    "CUE_INDEX = TOP + \"illustrative_examples/tenses/Data/Cue_index.csv\"\n",
    "OUTCOME_INDEX = TOP + \"illustrative_examples/tenses/Data/Outcome_index.csv\"\n",
    "DATA_DIR = TOP + 'illustrative_examples/tenses/Data/'\n",
    "GLOVE_PATH = os.path.join(DATA_DIR, 'glove.6B.100d.txt')\n",
    "WORD2VEC_PATH = os.path.join(DATA_DIR, 'GoogleNews-vectors-negative300.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_outcomes = 3 # number of most frequent outcomes to keep \n",
    "N_cues = 2000  # number of cues to keep (all alphabet letters)\n",
    "prop_valid = 1/10 # proportion of validation data\n",
    "prop_test = 1/10 # proportion of test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Prepare the data <a name=\"II\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 30000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>verb_forms</th>\n",
       "      <th>tenses</th>\n",
       "      <th>cues</th>\n",
       "      <th>outcomes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gifts of bulbs and trees will be much appreciated in the period september to december</td>\n",
       "      <td>will be appreciated</td>\n",
       "      <td>FutureSimple</td>\n",
       "      <td>gifts_of_bulbs_and_trees_much_in_the_period_september_to_december</td>\n",
       "      <td>FutureSimple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i will pick them up then</td>\n",
       "      <td>will pick</td>\n",
       "      <td>FutureSimple</td>\n",
       "      <td>i_them_up_then</td>\n",
       "      <td>FutureSimple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the shelters housing each flight will protect the equipment against a surprise attack by soviet ...</td>\n",
       "      <td>will protect</td>\n",
       "      <td>FutureSimple</td>\n",
       "      <td>the_shelters_housing_each_flight_the_equipment_against_a_surprise_attack_by_soviet_aircraft_or_m...</td>\n",
       "      <td>FutureSimple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what sort of shops will sell the product</td>\n",
       "      <td>will sell</td>\n",
       "      <td>FutureSimple</td>\n",
       "      <td>what_sort_of_shops_the_product</td>\n",
       "      <td>FutureSimple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>but he was angry</td>\n",
       "      <td>was</td>\n",
       "      <td>PastSimple</td>\n",
       "      <td>but_he_angry</td>\n",
       "      <td>PastSimple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             sentences  \\\n",
       "0                gifts of bulbs and trees will be much appreciated in the period september to december   \n",
       "1                                                                             i will pick them up then   \n",
       "2  the shelters housing each flight will protect the equipment against a surprise attack by soviet ...   \n",
       "3                                                             what sort of shops will sell the product   \n",
       "4                                                                                     but he was angry   \n",
       "\n",
       "            verb_forms        tenses  \\\n",
       "0  will be appreciated  FutureSimple   \n",
       "1            will pick  FutureSimple   \n",
       "2         will protect  FutureSimple   \n",
       "3            will sell  FutureSimple   \n",
       "4                  was    PastSimple   \n",
       "\n",
       "                                                                                                  cues  \\\n",
       "0                                    gifts_of_bulbs_and_trees_much_in_the_period_september_to_december   \n",
       "1                                                                                       i_them_up_then   \n",
       "2  the_shelters_housing_each_flight_the_equipment_against_a_surprise_attack_by_soviet_aircraft_or_m...   \n",
       "3                                                                       what_sort_of_shops_the_product   \n",
       "4                                                                                         but_he_angry   \n",
       "\n",
       "       outcomes  \n",
       "0  FutureSimple  \n",
       "1  FutureSimple  \n",
       "2  FutureSimple  \n",
       "3  FutureSimple  \n",
       "4    PastSimple  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tenses_full = pd.read_csv(TENSES_FULL_CSV)\n",
    "print(f'Number of examples: {len(tenses_full)}')\n",
    "tenses_full.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cues</th>\n",
       "      <th>outcomes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gifts_of_bulbs_and_trees_much_in_the_period_september_to_december</td>\n",
       "      <td>FutureSimple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i_them_up_then</td>\n",
       "      <td>FutureSimple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the_shelters_housing_each_flight_the_equipment_against_a_surprise_attack_by_soviet_aircraft_or_m...</td>\n",
       "      <td>FutureSimple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what_sort_of_shops_the_product</td>\n",
       "      <td>FutureSimple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>but_he_angry</td>\n",
       "      <td>PastSimple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  cues  \\\n",
       "0                                    gifts_of_bulbs_and_trees_much_in_the_period_september_to_december   \n",
       "1                                                                                       i_them_up_then   \n",
       "2  the_shelters_housing_each_flight_the_equipment_against_a_surprise_attack_by_soviet_aircraft_or_m...   \n",
       "3                                                                       what_sort_of_shops_the_product   \n",
       "4                                                                                         but_he_angry   \n",
       "\n",
       "       outcomes  \n",
       "0  FutureSimple  \n",
       "1  FutureSimple  \n",
       "2  FutureSimple  \n",
       "3  FutureSimple  \n",
       "4    PastSimple  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retain only the 'cues' and 'outcomes' columns\n",
    "tenses_full = tenses_full[['cues', 'outcomes']]\n",
    "tenses_full.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create index systems for the cues and outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the files containing the index systems\n",
    "pr.create_index_systems_from_df(data = tenses_full, \n",
    "                                cue_index_path = CUE_INDEX, \n",
    "                                outcome_index_path = OUTCOME_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{the: 1}\n",
      "{of: 2}\n",
      "{and: 3}\n",
      "{a: 4}\n",
      "{in: 5}\n"
     ]
    }
   ],
   "source": [
    "# Import the cue index system\n",
    "cue_to_index = pr.import_index_system(CUE_INDEX, N_tokens = N_cues)\n",
    "pr.display_dictionary(cue_to_index, start = 0, end = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FutureSimple': 1, 'PastSimple': 2, 'PresentSimple': 3}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the outcome index system\n",
    "outcome_to_index = pr.import_index_system(OUTCOME_INDEX)\n",
    "outcome_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'FutureSimple', 2: 'PastSimple', 3: 'PresentSimple'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reverse the cue dictionary\n",
    "index_to_cue = pr.reverse_dictionary(cue_to_index)\n",
    "# Reverse the outcome dictionary\n",
    "index_to_outcome = pr.reverse_dictionary(outcome_to_index)\n",
    "index_to_outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into training, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Number of rows in the original set is 30000\n",
      "- Number of rows in the training set is 24000\n",
      "- Number of rows in the validation set is 3000\n",
      "- Number of rows in the test set is 3000\n"
     ]
    }
   ],
   "source": [
    "# Create train, valid and test set files\n",
    "pr.df_train_valid_test_split(data = tenses_full, \n",
    "                             train_data_path = TENSES_TRAIN_CSV, \n",
    "                             valid_data_path = TENSES_VALID_CSV, \n",
    "                             test_data_path = TENSES_TEST_CSV, \n",
    "                             p_valid = prop_valid, \n",
    "                             p_test = prop_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train, valid and test sets\n",
    "tenses_train = pd.read_csv(TENSES_TRAIN_CSV, sep=',', na_filter = False)\n",
    "tenses_valid = pd.read_csv(TENSES_VALID_CSV, sep=',', na_filter = False)\n",
    "tenses_test = pd.read_csv(TENSES_VALID_CSV, sep=',', na_filter = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Feed-forward neural network model <a ID=\"III\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a simple FNN model with one-hot encoding (no embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a simple FNN with two hidden layers having 64 units "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 14s - loss: 1.0846 - accuracy: 0.3972 - val_loss: 1.0388 - val_accuracy: 0.4709\n",
      "Epoch 2/10\n",
      " - 14s - loss: 1.0208 - accuracy: 0.4818 - val_loss: 0.9160 - val_accuracy: 0.5107\n",
      "Epoch 3/10\n",
      " - 15s - loss: 0.9674 - accuracy: 0.5266 - val_loss: 0.8858 - val_accuracy: 0.5314\n",
      "Epoch 4/10\n",
      " - 14s - loss: 0.9365 - accuracy: 0.5544 - val_loss: 0.8770 - val_accuracy: 0.5344\n",
      "Epoch 5/10\n",
      " - 15s - loss: 0.9106 - accuracy: 0.5723 - val_loss: 0.8748 - val_accuracy: 0.5388\n",
      "Epoch 6/10\n",
      " - 14s - loss: 0.8858 - accuracy: 0.5897 - val_loss: 0.8867 - val_accuracy: 0.5388\n",
      "Epoch 7/10\n",
      " - 14s - loss: 0.8650 - accuracy: 0.6030 - val_loss: 0.9059 - val_accuracy: 0.5351\n",
      "Epoch 8/10\n",
      " - 14s - loss: 0.8512 - accuracy: 0.6141 - val_loss: 0.9223 - val_accuracy: 0.5328\n",
      "Epoch 9/10\n",
      " - 14s - loss: 0.8346 - accuracy: 0.6230 - val_loss: 0.9313 - val_accuracy: 0.5328\n",
      "Epoch 10/10\n",
      " - 12s - loss: 0.8200 - accuracy: 0.6323 - val_loss: 0.9462 - val_accuracy: 0.5291\n"
     ]
    }
   ],
   "source": [
    "### Hyperparameters to use\n",
    "p = {'max_len': 10,\n",
    "     'embedding_input': None,\n",
    "     'embedding_dim': None,\n",
    "     'epochs': 10, # number of iterations on the full set \n",
    "     'batch_size': 16, \n",
    "     'hidden_layers': 2, # number of hidden layers \n",
    "     'hidden_neuron':64, # number of neurons in the input layer \n",
    "     'lr': 0.0001, # learning rate       \n",
    "     'dropout': 0.3, \n",
    "     'optimizer': Adam, \n",
    "     'losses': categorical_crossentropy, \n",
    "     'activation': relu, \n",
    "     'last_activation': 'softmax'}\n",
    "\n",
    "# Model fitting\n",
    "FNN_onehot_hist, FNN_onehot_model = md.train(model = 'FNN',\n",
    "                                             data_train = tenses_train, \n",
    "                                             data_valid = tenses_valid, \n",
    "                                             cue_index = cue_to_index, \n",
    "                                             outcome_index = outcome_to_index, \n",
    "                                             verbose = 2,\n",
    "                                             metrics = ['accuracy'],\n",
    "                                             params = p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 64)                128064    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 132,419\n",
      "Trainable params: 132,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "FNN_onehot_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a simple FNN model with learnable embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a simple FNN with two hidden layers having 64 units "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 14s - loss: 1.0934 - accuracy: 0.3708 - val_loss: 1.0890 - val_accuracy: 0.4108\n",
      "Epoch 2/10\n",
      " - 13s - loss: 1.0571 - accuracy: 0.4466 - val_loss: 1.0547 - val_accuracy: 0.4649\n",
      "Epoch 3/10\n",
      " - 14s - loss: 1.0065 - accuracy: 0.4942 - val_loss: 0.9833 - val_accuracy: 0.4983\n",
      "Epoch 4/10\n",
      " - 13s - loss: 0.9681 - accuracy: 0.5235 - val_loss: 0.9272 - val_accuracy: 0.5144\n",
      "Epoch 5/10\n",
      " - 13s - loss: 0.9396 - accuracy: 0.5511 - val_loss: 0.8865 - val_accuracy: 0.5177\n",
      "Epoch 6/10\n",
      " - 13s - loss: 0.9125 - accuracy: 0.5705 - val_loss: 0.8598 - val_accuracy: 0.5241\n",
      "Epoch 7/10\n",
      " - 13s - loss: 0.8845 - accuracy: 0.5951 - val_loss: 0.8431 - val_accuracy: 0.5184\n",
      "Epoch 8/10\n",
      " - 13s - loss: 0.8603 - accuracy: 0.6093 - val_loss: 0.8428 - val_accuracy: 0.5187\n",
      "Epoch 9/10\n",
      " - 13s - loss: 0.8331 - accuracy: 0.6306 - val_loss: 0.8535 - val_accuracy: 0.5174\n",
      "Epoch 10/10\n",
      " - 13s - loss: 0.8082 - accuracy: 0.6456 - val_loss: 0.8735 - val_accuracy: 0.5147\n"
     ]
    }
   ],
   "source": [
    "### Hyperparameters to use\n",
    "p = {'max_len': 10,\n",
    "     'embedding_input': 'learn',\n",
    "     'embedding_dim': 16,\n",
    "     'epochs': 10, # number of iterations on the full set \n",
    "     'batch_size': 16, \n",
    "     'hidden_layers': 2, # number of hidden layers \n",
    "     'hidden_neuron':64, # number of neurons in the input layer \n",
    "     'lr': 0.0001, # learning rate       \n",
    "     'dropout': 0.3, \n",
    "     'optimizer': Adam, \n",
    "     'losses': categorical_crossentropy, \n",
    "     'activation': relu, \n",
    "     'last_activation': 'softmax'}\n",
    "\n",
    "# Model fitting\n",
    "FNN_onehot_hist, FNN_onehot_model = md.train(model = 'FNN',\n",
    "                                             data_train = tenses_train, \n",
    "                                             data_valid = tenses_valid, \n",
    "                                             cue_index = cue_to_index, \n",
    "                                             outcome_index = outcome_to_index, \n",
    "                                             verbose = 2,\n",
    "                                             metrics = ['accuracy'],\n",
    "                                             params = p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 10, 16)            32016     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                10304     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 46,675\n",
      "Trainable params: 46,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "FNN_embed_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a simple FNN model with pretrained embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a simple FNN with two hidden layers having 64 units "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 13s - loss: 1.1072 - accuracy: 0.3532 - val_loss: 1.0917 - val_accuracy: 0.3820\n",
      "Epoch 2/10\n",
      " - 13s - loss: 1.0888 - accuracy: 0.3756 - val_loss: 1.0966 - val_accuracy: 0.4081\n",
      "Epoch 3/10\n",
      " - 13s - loss: 1.0818 - accuracy: 0.3949 - val_loss: 1.0692 - val_accuracy: 0.4071\n",
      "Epoch 4/10\n",
      " - 13s - loss: 1.0742 - accuracy: 0.4064 - val_loss: 1.0752 - val_accuracy: 0.4201\n",
      "Epoch 5/10\n",
      " - 13s - loss: 1.0637 - accuracy: 0.4193 - val_loss: 1.0730 - val_accuracy: 0.4235\n",
      "Epoch 6/10\n",
      " - 13s - loss: 1.0556 - accuracy: 0.4363 - val_loss: 1.0846 - val_accuracy: 0.4315\n",
      "Epoch 7/10\n",
      " - 13s - loss: 1.0472 - accuracy: 0.4473 - val_loss: 1.0926 - val_accuracy: 0.4305\n",
      "Epoch 8/10\n",
      " - 13s - loss: 1.0381 - accuracy: 0.4544 - val_loss: 1.1201 - val_accuracy: 0.4392\n",
      "Epoch 9/10\n",
      " - 13s - loss: 1.0288 - accuracy: 0.4690 - val_loss: 1.1667 - val_accuracy: 0.4241\n",
      "Epoch 10/10\n",
      " - 14s - loss: 1.0177 - accuracy: 0.4773 - val_loss: 1.1163 - val_accuracy: 0.4372\n"
     ]
    }
   ],
   "source": [
    "### Hyperparameters to use\n",
    "p = {'max_len': 10,\n",
    "     'embedding_input': GLOVE_PATH,\n",
    "     'embedding_dim': None,\n",
    "     'epochs': 10, # number of iterations on the full set \n",
    "     'batch_size': 16, \n",
    "     'hidden_layers': 2, # number of hidden layers \n",
    "     'hidden_neuron':64, # number of neurons in the input layer \n",
    "     'lr': 0.0001, # learning rate       \n",
    "     'dropout': 0.3, \n",
    "     'optimizer': Adam, \n",
    "     'losses': categorical_crossentropy, \n",
    "     'activation': relu, \n",
    "     'last_activation': 'softmax'}\n",
    "\n",
    "# Model fitting\n",
    "FNN_glove_hist, FNN_glove_model = md.train(model = 'FNN',\n",
    "                                           data_train = tenses_train, \n",
    "                                           data_valid = tenses_valid, \n",
    "                                           cue_index = cue_to_index, \n",
    "                                           outcome_index = outcome_to_index, \n",
    "                                           verbose = 2,\n",
    "                                           metrics = ['accuracy'],\n",
    "                                           params = p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 10, 100)           200100    \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                64064     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 268,519\n",
      "Trainable params: 68,419\n",
      "Non-trainable params: 200,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "FNN_glove_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune the parameters to find a good model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Parameter tuning using grid search \n",
    "p = {'max_len': [None, 10, 20], # (x3)\n",
    "     'embedding_input': [None, 'learn', GLOVE_PATH], # (x3)\n",
    "     'embedding_dim': [None, 25, 50, 100], # (x4)\n",
    "     'epochs': [1, 5, 10, 20], # number of iterations on the full set (x5)\n",
    "     'batch_size': [16, 32, 64, 128, 256], # (x6)\n",
    "     'hidden_layers':[0, 1, 2], # number of hidden layers (x3)\n",
    "     'hidden_neuron':[16, 32, 64, 128], # number of neurons in the input layer (x4)\n",
    "     'lr': [0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01], # learning rate (x7)       \n",
    "     'dropout': [0, 0.1, 0.2, 0.3, 0.4], # (x5)\n",
    "     'optimizer': [Adam, RMSprop], # (x2)\n",
    "     'losses': [categorical_crossentropy], # (x1)\n",
    "     'activation':[relu, elu], # (x2)\n",
    "     'last_activation': ['softmax'] # (x1)\n",
    "     }\n",
    "TUNING_PATH = TOP + 'illustrative_examples/tenses/Results/grid_search_FNN_tenses.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 out of 13: {'max_len': 20, 'embedding_input': 'learn', 'embedding_dim': 100, 'epochs': 20, 'batch_size': 32, 'hidden_layers': 2, 'hidden_neuron': 32, 'lr': 0.001, 'dropout': 0.3, 'optimizer': <class 'keras.optimizers.RMSprop'>, 'losses': <function categorical_crossentropy at 0x7f7650cef488>, 'activation': <function relu at 0x7f7650cbdd90>, 'last_activation': 'softmax'}\n",
      "\n",
      "Iteration 2 out of 13: {'max_len': 20, 'embedding_input': 'learn', 'embedding_dim': 100, 'epochs': 20, 'batch_size': 32, 'hidden_layers': 2, 'hidden_neuron': 64, 'lr': 0.0005, 'dropout': 0.3, 'optimizer': <class 'keras.optimizers.Adam'>, 'losses': <function categorical_crossentropy at 0x7f7650cef488>, 'activation': <function elu at 0x7f7650cbdb70>, 'last_activation': 'softmax'}\n",
      "\n",
      "Iteration 3 out of 13: {'max_len': 20, 'embedding_input': 'learn', 'embedding_dim': 50, 'epochs': 5, 'batch_size': 256, 'hidden_layers': 1, 'hidden_neuron': 16, 'lr': 0.002, 'dropout': 0.4, 'optimizer': <class 'keras.optimizers.RMSprop'>, 'losses': <function categorical_crossentropy at 0x7f7650cef488>, 'activation': <function relu at 0x7f7650cbdd90>, 'last_activation': 'softmax'}\n",
      "\n",
      "Iteration 4 out of 13: {'max_len': 20, 'embedding_input': '/media/adnane/HDD drive/Adnane/PostDoc_ooominds/Programming/Deep_text_modelling_package_repo_tests/illustrative_examples/tenses/Data/glove.6B.100d.txt', 'embedding_dim': 100, 'epochs': 1, 'batch_size': 64, 'hidden_layers': 1, 'hidden_neuron': 16, 'lr': 0.001, 'dropout': 0.4, 'optimizer': <class 'keras.optimizers.RMSprop'>, 'losses': <function categorical_crossentropy at 0x7f7650cef488>, 'activation': <function elu at 0x7f7650cbdb70>, 'last_activation': 'softmax'}\n",
      "\n",
      "Iteration 5 out of 13: {'max_len': None, 'embedding_input': None, 'embedding_dim': None, 'epochs': 1, 'batch_size': 16, 'hidden_layers': 1, 'hidden_neuron': 64, 'lr': 0.0005, 'dropout': 0.3, 'optimizer': <class 'keras.optimizers.Adam'>, 'losses': <function categorical_crossentropy at 0x7f7650cef488>, 'activation': <function relu at 0x7f7650cbdd90>, 'last_activation': 'softmax'}\n",
      "\n",
      "Iteration 6 out of 13: {'max_len': 20, 'embedding_input': None, 'embedding_dim': None, 'epochs': 20, 'batch_size': 32, 'hidden_layers': 0, 'hidden_neuron': 128, 'lr': 0.0001, 'dropout': 0.3, 'optimizer': <class 'keras.optimizers.Adam'>, 'losses': <function categorical_crossentropy at 0x7f7650cef488>, 'activation': None, 'last_activation': 'softmax'}\n",
      "\n",
      "Iteration 7 out of 13: {'max_len': 10, 'embedding_input': 'learn', 'embedding_dim': 25, 'epochs': 5, 'batch_size': 64, 'hidden_layers': 2, 'hidden_neuron': 16, 'lr': 0.002, 'dropout': 0.1, 'optimizer': <class 'keras.optimizers.Adam'>, 'losses': <function categorical_crossentropy at 0x7f7650cef488>, 'activation': <function elu at 0x7f7650cbdb70>, 'last_activation': 'softmax'}\n",
      "\n",
      "Iteration 8 out of 13: {'max_len': 20, 'embedding_input': 'learn', 'embedding_dim': 25, 'epochs': 10, 'batch_size': 128, 'hidden_layers': 2, 'hidden_neuron': 16, 'lr': 0.001, 'dropout': 0.3, 'optimizer': <class 'keras.optimizers.Adam'>, 'losses': <function categorical_crossentropy at 0x7f7650cef488>, 'activation': <function relu at 0x7f7650cbdd90>, 'last_activation': 'softmax'}\n",
      "\n",
      "Iteration 9 out of 13: {'max_len': 10, 'embedding_input': None, 'embedding_dim': None, 'epochs': 1, 'batch_size': 32, 'hidden_layers': 2, 'hidden_neuron': 128, 'lr': 0.0001, 'dropout': 0.2, 'optimizer': <class 'keras.optimizers.RMSprop'>, 'losses': <function categorical_crossentropy at 0x7f7650cef488>, 'activation': <function relu at 0x7f7650cbdd90>, 'last_activation': 'softmax'}\n",
      "\n",
      "Iteration 10 out of 13: {'max_len': 10, 'embedding_input': None, 'embedding_dim': None, 'epochs': 10, 'batch_size': 32, 'hidden_layers': 2, 'hidden_neuron': 128, 'lr': 0.0002, 'dropout': 0, 'optimizer': <class 'keras.optimizers.Adam'>, 'losses': <function categorical_crossentropy at 0x7f7650cef488>, 'activation': <function elu at 0x7f7650cbdb70>, 'last_activation': 'softmax'}\n",
      "\n",
      "Iteration 11 out of 13: {'max_len': 10, 'embedding_input': 'learn', 'embedding_dim': 50, 'epochs': 1, 'batch_size': 128, 'hidden_layers': 0, 'hidden_neuron': 128, 'lr': 0.002, 'dropout': 0, 'optimizer': <class 'keras.optimizers.RMSprop'>, 'losses': <function categorical_crossentropy at 0x7f7650cef488>, 'activation': None, 'last_activation': 'softmax'}\n",
      "\n",
      "Iteration 12 out of 13: {'max_len': 10, 'embedding_input': 'learn', 'embedding_dim': 50, 'epochs': 20, 'batch_size': 32, 'hidden_layers': 2, 'hidden_neuron': 128, 'lr': 0.0001, 'dropout': 0.1, 'optimizer': <class 'keras.optimizers.RMSprop'>, 'losses': <function categorical_crossentropy at 0x7f7650cef488>, 'activation': <function elu at 0x7f7650cbdb70>, 'last_activation': 'softmax'}\n",
      "\n",
      "Iteration 13 out of 13: {'max_len': 10, 'embedding_input': 'learn', 'embedding_dim': 50, 'epochs': 20, 'batch_size': 128, 'hidden_layers': 1, 'hidden_neuron': 128, 'lr': 0.0001, 'dropout': 0, 'optimizer': <class 'keras.optimizers.Adam'>, 'losses': <function categorical_crossentropy at 0x7f7650cef488>, 'activation': <function relu at 0x7f7650cbdd90>, 'last_activation': 'softmax'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Grid search \n",
    "md.grid_search(model = 'FNN', \n",
    "               data_train = tenses_train, \n",
    "               data_valid = tenses_valid, \n",
    "               cue_index = cue_to_index, \n",
    "               outcome_index = outcome_to_index,\n",
    "               params = p,\n",
    "               prop_grid = 3e-5, \n",
    "               tuning_output_file = TUNING_PATH,\n",
    "               num_threads = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the grid search file to analyse the results \n",
    "gs_results = pd.read_csv(TUNING_PATH, index_col = False)\n",
    "\n",
    "# get the number of parameter combinations that were processed\n",
    "len(gs_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_len</th>\n",
       "      <th>embedding_input</th>\n",
       "      <th>embedding_dim</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>hidden_neuron</th>\n",
       "      <th>lr</th>\n",
       "      <th>dropout</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>...</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1score</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>val_f1score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>learn</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>&lt;class 'keras.optimizers.RMSprop'&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>1.047667</td>\n",
       "      <td>0.439417</td>\n",
       "      <td>0.430142</td>\n",
       "      <td>0.091167</td>\n",
       "      <td>0.142780</td>\n",
       "      <td>0.922010</td>\n",
       "      <td>0.511761</td>\n",
       "      <td>0.676267</td>\n",
       "      <td>0.193212</td>\n",
       "      <td>0.296398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>learn</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>&lt;class 'keras.optimizers.RMSprop'&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939916</td>\n",
       "      <td>0.555708</td>\n",
       "      <td>0.663701</td>\n",
       "      <td>0.322333</td>\n",
       "      <td>0.429357</td>\n",
       "      <td>0.990584</td>\n",
       "      <td>0.543683</td>\n",
       "      <td>0.627753</td>\n",
       "      <td>0.321573</td>\n",
       "      <td>0.422796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.0</td>\n",
       "      <td>learn</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>&lt;class 'keras.optimizers.RMSprop'&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0.843930</td>\n",
       "      <td>0.620417</td>\n",
       "      <td>0.699993</td>\n",
       "      <td>0.467167</td>\n",
       "      <td>0.558022</td>\n",
       "      <td>1.110330</td>\n",
       "      <td>0.526546</td>\n",
       "      <td>0.574827</td>\n",
       "      <td>0.385081</td>\n",
       "      <td>0.459701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>learn</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>&lt;class 'keras.optimizers.RMSprop'&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0.745011</td>\n",
       "      <td>0.675458</td>\n",
       "      <td>0.751865</td>\n",
       "      <td>0.559958</td>\n",
       "      <td>0.639852</td>\n",
       "      <td>1.285845</td>\n",
       "      <td>0.510417</td>\n",
       "      <td>0.548787</td>\n",
       "      <td>0.408266</td>\n",
       "      <td>0.466841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>learn</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>&lt;class 'keras.optimizers.RMSprop'&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666116</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.784475</td>\n",
       "      <td>0.617208</td>\n",
       "      <td>0.689186</td>\n",
       "      <td>1.517434</td>\n",
       "      <td>0.504032</td>\n",
       "      <td>0.530794</td>\n",
       "      <td>0.418347</td>\n",
       "      <td>0.466889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_len embedding_input  embedding_dim  epochs  batch_size  hidden_layers  \\\n",
       "0     20.0           learn            100       1          32              2   \n",
       "1     20.0           learn            100       2          32              2   \n",
       "2     20.0           learn            100       3          32              2   \n",
       "3     20.0           learn            100       4          32              2   \n",
       "4     20.0           learn            100       5          32              2   \n",
       "\n",
       "   hidden_neuron     lr  dropout                           optimizer  ...  \\\n",
       "0             32  0.001      0.3  <class 'keras.optimizers.RMSprop'>  ...   \n",
       "1             32  0.001      0.3  <class 'keras.optimizers.RMSprop'>  ...   \n",
       "2             32  0.001      0.3  <class 'keras.optimizers.RMSprop'>  ...   \n",
       "3             32  0.001      0.3  <class 'keras.optimizers.RMSprop'>  ...   \n",
       "4             32  0.001      0.3  <class 'keras.optimizers.RMSprop'>  ...   \n",
       "\n",
       "       loss       acc precision    recall   f1score  val_loss   val_acc  \\\n",
       "0  1.047667  0.439417  0.430142  0.091167  0.142780  0.922010  0.511761   \n",
       "1  0.939916  0.555708  0.663701  0.322333  0.429357  0.990584  0.543683   \n",
       "2  0.843930  0.620417  0.699993  0.467167  0.558022  1.110330  0.526546   \n",
       "3  0.745011  0.675458  0.751865  0.559958  0.639852  1.285845  0.510417   \n",
       "4  0.666116  0.712500  0.784475  0.617208  0.689186  1.517434  0.504032   \n",
       "\n",
       "   val_precision  val_recall  val_f1score  \n",
       "0       0.676267    0.193212     0.296398  \n",
       "1       0.627753    0.321573     0.422796  \n",
       "2       0.574827    0.385081     0.459701  \n",
       "3       0.548787    0.408266     0.466841  \n",
       "4       0.530794    0.418347     0.466889  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the dataframe containing the tuning results\n",
    "gs_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['max_len', 'embedding_input', 'embedding_dim', 'epochs', 'batch_size',\n",
       "       'hidden_layers', 'hidden_neuron', 'lr', 'dropout', 'optimizer',\n",
       "       'losses', 'activation', 'last_activation', 'loss', 'acc', 'precision',\n",
       "       'recall', 'f1score', 'val_loss', 'val_acc', 'val_precision',\n",
       "       'val_recall', 'val_f1score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Highest validation accuracy: 0.5436828136444092\n",
      "- Highest validation f1-score: 0.8663970999999999\n"
     ]
    }
   ],
   "source": [
    "# get the highest result for any metric\n",
    "print(f\"- Highest validation accuracy: {gs_results['val_acc'].max()}\")\n",
    "print(f\"- Highest validation f1-score: {gs_results['f1score'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the index of the combination with the best result\n",
    "i_best = gs_results['val_acc'].argmax()\n",
    "i_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max_len                                            20\n",
       "embedding_input                                 learn\n",
       "embedding_dim                                     100\n",
       "epochs                                              2\n",
       "batch_size                                         32\n",
       "hidden_layers                                       2\n",
       "hidden_neuron                                      32\n",
       "lr                                              0.001\n",
       "dropout                                           0.3\n",
       "optimizer          <class 'keras.optimizers.RMSprop'>\n",
       "                                  ...                \n",
       "loss                                         0.939916\n",
       "acc                                          0.555708\n",
       "precision                                    0.663701\n",
       "recall                                       0.322333\n",
       "f1score                                      0.429357\n",
       "val_loss                                     0.990584\n",
       "val_acc                                      0.543683\n",
       "val_precision                                0.627753\n",
       "val_recall                                   0.321573\n",
       "val_f1score                                  0.422796\n",
       "Name: 1, Length: 23, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the best paramaters\n",
    "gs_results.iloc[i_best, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retraining with the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " - 7s - loss: 1.0351 - accuracy: 0.4562 - val_loss: 0.9412 - val_accuracy: 0.5218\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.9358 - accuracy: 0.5590 - val_loss: 0.9503 - val_accuracy: 0.5370\n"
     ]
    }
   ],
   "source": [
    "### Hyperparameters to use\n",
    "p = {'max_len': 20,\n",
    "     'embedding_input': 'learn',\n",
    "     'embedding_dim': 100,\n",
    "     'epochs': 2, # number of iterations on the full set \n",
    "     'batch_size': 32, \n",
    "     'hidden_layers': 2, # number of hidden layers \n",
    "     'hidden_neuron': 32, # number of neurons in the input layer \n",
    "     'lr': 0.001, # learning rate       \n",
    "     'dropout': 0.3, \n",
    "     'optimizer': RMSprop, \n",
    "     'losses': categorical_crossentropy, \n",
    "     'activation': relu, \n",
    "     'last_activation': 'softmax'}\n",
    "\n",
    "# Model fitting\n",
    "FNN_hist, FNN_model = md.train(model = 'FNN',\n",
    "                               data_train = tenses_train, \n",
    "                               data_valid = tenses_valid, \n",
    "                               cue_index = cue_to_index, \n",
    "                               outcome_index = outcome_to_index, \n",
    "                               verbose = 2,\n",
    "                               metrics = ['accuracy'],\n",
    "                               params = p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and training history\n",
    "MODEL_PATH = TOP + 'illustrative_examples/tenses/Results/FNN_tenses.h5'\n",
    "HISTORY_PATH = TOP + 'illustrative_examples/tenses/Results/FNN_history_dict_tenses'\n",
    "md.export_model(model = FNN_model, path = MODEL_PATH)  # creates a HDF5 file \n",
    "md.export_history(history_dict = FNN_hist, path = HISTORY_PATH)\n",
    "del FNN_model, FNN_hist  # delete the existing model and history dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and training history\n",
    "MODEL_PATH = TOP + 'illustrative_examples/tenses/Results/FNN_tenses.h5'\n",
    "HISTORY_PATH = TOP + 'illustrative_examples/tenses/Results/FNN_history_dict_tenses'\n",
    "FNN_model = md.import_model(MODEL_PATH)\n",
    "FNN_history_dict = md.import_history(path = HISTORY_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Training loss in the last epoch: 0.9357744853496551\n",
      "- Training accuracy in the last epoch: 0.5590417\n",
      "- Validation loss in the last epoch: 0.9502525925636292\n",
      "- Validation accuracy in the last epoch: 0.5369623899459839\n"
     ]
    }
   ],
   "source": [
    "# Performance on the last epoch of the training set\n",
    "print(f\"- Training loss in the last epoch: {FNN_history_dict['loss'][-1]}\")\n",
    "print(f\"- Training accuracy in the last epoch: {FNN_history_dict['accuracy'][-1]}\")\n",
    "\n",
    "# Performance on the last epoch of the validation set\n",
    "print(f\"- Validation loss in the last epoch: {FNN_history_dict['val_loss'][-1]}\")\n",
    "print(f\"- Validation accuracy in the last epoch: {FNN_history_dict['val_accuracy'][-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate plots to assess the performance of the NN\n",
    "ev.plot_learning_curve(history_dict = FNN_history_dict, metric = 'accuracy', set = 'train_valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FutureSimple': 0.85951036, 'PastSimple': 0.025730181, 'PresentSimple': 0.11475951}\n"
     ]
    }
   ],
   "source": [
    "# Test prediction for a single given cue sequence. Model expect input as array of shape (1, N_cues) \n",
    "cue1_seq = 'I_you_tomorrow' # context from the sentence 'I will meet you tomorrow'\n",
    "outcome1_prob_pred = ev.predict_proba_oneevent_FNN(model = FNN_model, \n",
    "                                                   cue_seq = cue1_seq,   \n",
    "                                                   cue_index = cue_to_index,\n",
    "                                                   max_len = 20,\n",
    "                                                   vector_encoding = 'embedding')\n",
    "print({index_to_outcome[j+1]:outcome1_prob_pred[j] for j in range(len(outcome1_prob_pred))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "prob_pred = ev.predict_proba_eventfile_FNN(model = FNN_model, \n",
    "                                           data_test = tenses_test,  \n",
    "                                           cue_index = cue_to_index, \n",
    "                                           outcome_index = outcome_to_index,\n",
    "                                           max_len = 20,\n",
    "                                           vector_encoding = 'embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5366666666666666"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# True responses to compare the predictions to\n",
    "y_test = tenses_test.replace({'outcomes': outcome_to_index})['outcomes']\n",
    "y_pred = np.argmax(prob_pred, axis=1)+1\n",
    "\n",
    "# Overall test accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FutureSimple': 0.5292368681863231, 'PastSimple': 0.6075433231396534, 'PresentSimple': 0.4752475247524752}\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy per class\n",
    "cmat = confusion_matrix(y_test, y_pred, labels = list(outcome_to_index.values())) # Confusion matrix\n",
    "cmat_diag = cmat.diagonal()/cmat.sum(axis=1)\n",
    "print({index_to_outcome[j+1]:cmat_diag[j] for j in range(len(cmat_diag))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Long short-term memory model <a ID=\"IV\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a simple LSTM model with one-hot encoding (no embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a simple LSTM that has 64 hidden units "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 29s - loss: 1.0717 - accuracy: 0.4199 - val_loss: 1.0076 - val_accuracy: 0.4552\n",
      "Epoch 2/10\n",
      " - 28s - loss: 1.0102 - accuracy: 0.4786 - val_loss: 1.0370 - val_accuracy: 0.4783\n",
      "Epoch 3/10\n",
      " - 29s - loss: 0.9916 - accuracy: 0.4949 - val_loss: 1.0423 - val_accuracy: 0.4923\n",
      "Epoch 4/10\n",
      " - 31s - loss: 0.9761 - accuracy: 0.5138 - val_loss: 1.0351 - val_accuracy: 0.5023\n",
      "Epoch 5/10\n",
      " - 30s - loss: 0.9598 - accuracy: 0.5315 - val_loss: 1.0125 - val_accuracy: 0.5147\n",
      "Epoch 6/10\n",
      " - 30s - loss: 0.9472 - accuracy: 0.5458 - val_loss: 0.9765 - val_accuracy: 0.5217\n",
      "Epoch 7/10\n",
      " - 29s - loss: 0.9361 - accuracy: 0.5520 - val_loss: 0.9451 - val_accuracy: 0.5254\n",
      "Epoch 8/10\n",
      " - 30s - loss: 0.9284 - accuracy: 0.5610 - val_loss: 0.9190 - val_accuracy: 0.5261\n",
      "Epoch 9/10\n",
      " - 29s - loss: 0.9211 - accuracy: 0.5642 - val_loss: 0.8992 - val_accuracy: 0.5274\n",
      "Epoch 10/10\n",
      " - 28s - loss: 0.9162 - accuracy: 0.5673 - val_loss: 0.8859 - val_accuracy: 0.5227\n"
     ]
    }
   ],
   "source": [
    "### Build a simple LSTM that has 64 hidden units \n",
    "p = {'max_len': 10,\n",
    "     'embedding_input': None,\n",
    "     'embedding_dim': None,\n",
    "     'epochs': 10, # number of iterations on the full set \n",
    "     'batch_size': 16, \n",
    "     'hidden_neuron': 64, # number of neurons in the input layer \n",
    "     'lr': 0.0001, # learning rate       \n",
    "     'dropout': 0.2, \n",
    "     'optimizer': RMSprop, \n",
    "     'losses': categorical_crossentropy, \n",
    "     'last_activation': 'softmax'}\n",
    "\n",
    "# Model fitting\n",
    "LSTM_onehot_hist, LSTM_onehot_model = md.train(model = 'LSTM', \n",
    "                                               data_train = tenses_train, \n",
    "                                               data_valid = tenses_valid, \n",
    "                                               cue_index = cue_to_index, \n",
    "                                               outcome_index = outcome_to_index, \n",
    "                                               verbose = 2,\n",
    "                                               metrics = ['accuracy'],\n",
    "                                               params = p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 64)                528640    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 528,835\n",
      "Trainable params: 528,835\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LSTM_onehot_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a simple LSTM model with learnable embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a simple LSTM that has 64 hidden units "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 29s - loss: 1.0748 - accuracy: 0.4089 - val_loss: 1.0170 - val_accuracy: 0.4509\n",
      "Epoch 2/10\n",
      " - 28s - loss: 1.0206 - accuracy: 0.4698 - val_loss: 1.0128 - val_accuracy: 0.4753\n",
      "Epoch 3/10\n",
      " - 27s - loss: 1.0026 - accuracy: 0.4836 - val_loss: 1.0035 - val_accuracy: 0.4926\n",
      "Epoch 4/10\n",
      " - 28s - loss: 0.9893 - accuracy: 0.4945 - val_loss: 0.9871 - val_accuracy: 0.4987\n",
      "Epoch 5/10\n",
      " - 30s - loss: 0.9783 - accuracy: 0.5053 - val_loss: 0.9674 - val_accuracy: 0.5027\n",
      "Epoch 6/10\n",
      " - 28s - loss: 0.9677 - accuracy: 0.5185 - val_loss: 0.9524 - val_accuracy: 0.5130\n",
      "Epoch 7/10\n",
      " - 29s - loss: 0.9555 - accuracy: 0.5322 - val_loss: 0.9412 - val_accuracy: 0.5184\n",
      "Epoch 8/10\n",
      " - 29s - loss: 0.9453 - accuracy: 0.5437 - val_loss: 0.9289 - val_accuracy: 0.5267\n",
      "Epoch 9/10\n",
      " - 29s - loss: 0.9375 - accuracy: 0.5510 - val_loss: 0.9129 - val_accuracy: 0.5291\n",
      "Epoch 10/10\n",
      " - 29s - loss: 0.9306 - accuracy: 0.5569 - val_loss: 0.9014 - val_accuracy: 0.5328\n"
     ]
    }
   ],
   "source": [
    "### Build a simple LSTM that has 64 hidden units \n",
    "p = {'max_len': 10,\n",
    "     'embedding_input': 'learn',\n",
    "     'embedding_dim': 16,\n",
    "     'epochs': 10, # number of iterations on the full set \n",
    "     'batch_size': 16, \n",
    "     'hidden_neuron': 64, # number of neurons in the input layer \n",
    "     'lr': 0.0001, # learning rate       \n",
    "     'dropout': 0.2, \n",
    "     'optimizer': RMSprop, \n",
    "     'losses': categorical_crossentropy, \n",
    "     'last_activation': 'softmax'}\n",
    "\n",
    "# Model fitting\n",
    "LSTM_embed_hist, LSTM_embed_model = md.train(model = 'LSTM', \n",
    "                                             data_train = tenses_train, \n",
    "                                             data_valid = tenses_valid, \n",
    "                                             cue_index = cue_to_index, \n",
    "                                             outcome_index = outcome_to_index, \n",
    "                                             verbose = 2,\n",
    "                                             metrics = ['accuracy'],\n",
    "                                             params = p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 10, 16)            32016     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                20736     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 52,947\n",
      "Trainable params: 52,947\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LSTM_embed_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a simple LSTM model with pretrained embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a simple LSTM that has 64 hidden units "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 30s - loss: 1.0937 - accuracy: 0.3759 - val_loss: 1.0813 - val_accuracy: 0.4168\n",
      "Epoch 2/10\n",
      " - 27s - loss: 1.0790 - accuracy: 0.4045 - val_loss: 1.0422 - val_accuracy: 0.4328\n",
      "Epoch 3/10\n",
      " - 28s - loss: 1.0641 - accuracy: 0.4304 - val_loss: 1.0309 - val_accuracy: 0.4439\n",
      "Epoch 4/10\n",
      " - 29s - loss: 1.0552 - accuracy: 0.4421 - val_loss: 1.0257 - val_accuracy: 0.4499\n",
      "Epoch 5/10\n",
      " - 29s - loss: 1.0462 - accuracy: 0.4495 - val_loss: 1.0206 - val_accuracy: 0.4586\n",
      "Epoch 6/10\n",
      " - 28s - loss: 1.0391 - accuracy: 0.4553 - val_loss: 1.0184 - val_accuracy: 0.4639\n",
      "Epoch 7/10\n",
      " - 28s - loss: 1.0346 - accuracy: 0.4595 - val_loss: 1.0074 - val_accuracy: 0.4652\n",
      "Epoch 8/10\n",
      " - 28s - loss: 1.0292 - accuracy: 0.4694 - val_loss: 0.9955 - val_accuracy: 0.4686\n",
      "Epoch 9/10\n",
      " - 29s - loss: 1.0239 - accuracy: 0.4726 - val_loss: 0.9813 - val_accuracy: 0.4696\n",
      "Epoch 10/10\n",
      " - 28s - loss: 1.0198 - accuracy: 0.4749 - val_loss: 0.9784 - val_accuracy: 0.4672\n"
     ]
    }
   ],
   "source": [
    "### Build a simple LSTM that has 64 hidden units \n",
    "p = {'max_len': 10,\n",
    "     'embedding_input': GLOVE_PATH,\n",
    "     'embedding_dim': None,\n",
    "     'epochs': 10, # number of iterations on the full set \n",
    "     'batch_size': 16, \n",
    "     'hidden_neuron': 64, # number of neurons in the input layer \n",
    "     'lr': 0.0001, # learning rate       \n",
    "     'dropout': 0.2, \n",
    "     'optimizer': RMSprop, \n",
    "     'losses': categorical_crossentropy, \n",
    "     'last_activation': 'softmax'}\n",
    "\n",
    "# Model fitting\n",
    "LSTM_glove_hist, LSTM_glove_model = md.train(model = 'LSTM', \n",
    "                                             data_train = tenses_train, \n",
    "                                             data_valid = tenses_valid, \n",
    "                                             cue_index = cue_to_index, \n",
    "                                             outcome_index = outcome_to_index, \n",
    "                                             verbose = 2,\n",
    "                                             metrics = ['accuracy'],\n",
    "                                             params = p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 10, 100)           200100    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 64)                42240     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 242,535\n",
      "Trainable params: 42,435\n",
      "Non-trainable params: 200,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LSTM_glove_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune the parameters to find a good model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Parameter tuning using grid search \n",
    "p = {'max_len': [10, 20], # (x2)\n",
    "     'embedding_input': [None, 'learn', GLOVE_PATH], # (x3)\n",
    "     'embedding_dim': [None, 25, 50, 100], # (x4)\n",
    "     'epochs': [1, 5, 10, 20], # number of iterations on the full set (x4)\n",
    "     'batch_size': [16, 32, 64, 128, 256], # (x5)\n",
    "     'hidden_neuron':[16, 32, 64, 128], # number of neurons in the input layer (x4)\n",
    "     'lr': [0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01], # learning rate (x7)       \n",
    "     'dropout': [0, 0.1, 0.2, 0.3, 0.4], # (x5)\n",
    "     'optimizer': [Adam, Nadam, RMSprop, SGD], # (x4)\n",
    "     'losses': [categorical_crossentropy], # (x1)\n",
    "     'last_activation': ['softmax'] # (x1)\n",
    "     }\n",
    "TUNING_PATH = TOP + 'illustrative_examples/tenses/Results/grid_search_LSTM_tenses.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 out of 11: {'max_len': 20, 'embedding_input': 'learn', 'embedding_dim': 100, 'epochs': 5, 'batch_size': 128, 'hidden_neuron': 16, 'lr': 0.001, 'dropout': 0.2, 'optimizer': <class 'keras.optimizers.Nadam'>, 'losses': <function categorical_crossentropy at 0x7f2f48874510>, 'last_activation': 'softmax'}\n",
      "\n",
      "Iteration 2 out of 11: {'max_len': 20, 'embedding_input': 'learn', 'embedding_dim': 50, 'epochs': 5, 'batch_size': 16, 'hidden_neuron': 32, 'lr': 0.0001, 'dropout': 0.2, 'optimizer': <class 'keras.optimizers.Nadam'>, 'losses': <function categorical_crossentropy at 0x7f2f48874510>, 'last_activation': 'softmax'}\n",
      "\n",
      "Iteration 3 out of 11: {'max_len': 10, 'embedding_input': '/media/adnane/HDD drive/Adnane/PostDoc_ooominds/Programming/Deep_text_modelling_package_repo/illustrative_examples/tenses/Data/glove.6B.100d.txt', 'embedding_dim': 100, 'epochs': 10, 'batch_size': 128, 'hidden_neuron': 32, 'lr': 0.01, 'dropout': 0.4, 'optimizer': <class 'keras.optimizers.Adam'>, 'losses': <function categorical_crossentropy at 0x7f2f48874510>, 'last_activation': 'softmax'}\n",
      "\n",
      "Iteration 4 out of 11: {'max_len': 10, 'embedding_input': 'learn', 'embedding_dim': 50, 'epochs': 5, 'batch_size': 16, 'hidden_neuron': 32, 'lr': 0.005, 'dropout': 0.2, 'optimizer': <class 'keras.optimizers.Adam'>, 'losses': <function categorical_crossentropy at 0x7f2f48874510>, 'last_activation': 'softmax'}\n",
      "\n",
      "Iteration 5 out of 11: {'max_len': 10, 'embedding_input': 'learn', 'embedding_dim': 50, 'epochs': 1, 'batch_size': 16, 'hidden_neuron': 64, 'lr': 0.001, 'dropout': 0.3, 'optimizer': <class 'keras.optimizers.Adam'>, 'losses': <function categorical_crossentropy at 0x7f2f48874510>, 'last_activation': 'softmax'}\n",
      "\n",
      "Iteration 6 out of 11: {'max_len': 20, 'embedding_input': 'learn', 'embedding_dim': 100, 'epochs': 10, 'batch_size': 32, 'hidden_neuron': 64, 'lr': 0.01, 'dropout': 0.2, 'optimizer': <class 'keras.optimizers.Adam'>, 'losses': <function categorical_crossentropy at 0x7f2f48874510>, 'last_activation': 'softmax'}\n",
      "\n",
      "Iteration 7 out of 11: {'max_len': 10, 'embedding_input': 'learn', 'embedding_dim': 50, 'epochs': 1, 'batch_size': 64, 'hidden_neuron': 64, 'lr': 0.0001, 'dropout': 0.3, 'optimizer': <class 'keras.optimizers.Nadam'>, 'losses': <function categorical_crossentropy at 0x7f2f48874510>, 'last_activation': 'softmax'}\n",
      "\n",
      "Iteration 8 out of 11: {'max_len': 10, 'embedding_input': None, 'embedding_dim': None, 'epochs': 5, 'batch_size': 16, 'hidden_neuron': 32, 'lr': 0.01, 'dropout': 0, 'optimizer': <class 'keras.optimizers.SGD'>, 'losses': <function categorical_crossentropy at 0x7f2f48874510>, 'last_activation': 'softmax'}\n",
      "\n",
      "Iteration 9 out of 11: {'max_len': 10, 'embedding_input': None, 'embedding_dim': None, 'epochs': 20, 'batch_size': 128, 'hidden_neuron': 128, 'lr': 0.005, 'dropout': 0, 'optimizer': <class 'keras.optimizers.SGD'>, 'losses': <function categorical_crossentropy at 0x7f2f48874510>, 'last_activation': 'softmax'}\n",
      "\n",
      "Iteration 10 out of 11: {'max_len': 10, 'embedding_input': None, 'embedding_dim': None, 'epochs': 10, 'batch_size': 256, 'hidden_neuron': 32, 'lr': 0.01, 'dropout': 0.1, 'optimizer': <class 'keras.optimizers.Nadam'>, 'losses': <function categorical_crossentropy at 0x7f2f48874510>, 'last_activation': 'softmax'}\n",
      "\n",
      "Iteration 11 out of 11: {'max_len': 20, 'embedding_input': None, 'embedding_dim': None, 'epochs': 20, 'batch_size': 256, 'hidden_neuron': 16, 'lr': 0.01, 'dropout': 0, 'optimizer': <class 'keras.optimizers.Adam'>, 'losses': <function categorical_crossentropy at 0x7f2f48874510>, 'last_activation': 'softmax'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Grid search \n",
    "md.grid_search(model = 'LSTM',\n",
    "               data_train = tenses_train, \n",
    "               data_valid = tenses_valid, \n",
    "               cue_index = cue_to_index, \n",
    "               outcome_index = outcome_to_index,\n",
    "               params = p,\n",
    "               prop_grid = 1e-4, \n",
    "               tuning_output_file = TUNING_PATH,  \n",
    "               num_threads = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the grid search file to analyse the results \n",
    "gs_results = pd.read_csv(TUNING_PATH, index_col = False)\n",
    "\n",
    "# get the number of parameter combinations that were processed\n",
    "len(gs_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Highest validation accuracy: 0.5372869372367859\n",
      "- Highest validation f1-score: 0.84058493\n"
     ]
    }
   ],
   "source": [
    "# get the highest result for any metric\n",
    "print(f\"- Highest validation accuracy: {gs_results['val_acc'].max()}\")\n",
    "print(f\"- Highest validation f1-score: {gs_results['f1score'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the index of the combination with the best result\n",
    "i_best = gs_results['val_acc'].argmax()\n",
    "i_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max_len                                                               10\n",
       "embedding_input                                                   onehot\n",
       "embedding_dim                                                          0\n",
       "epochs                                                                 1\n",
       "batch_size                                                           256\n",
       "hidden_neuron                                                         32\n",
       "lr                                                                  0.01\n",
       "dropout                                                              0.1\n",
       "optimizer                               <class 'keras.optimizers.Nadam'>\n",
       "losses             <function categorical_crossentropy at 0x7f2f48874510>\n",
       "                                           ...                          \n",
       "loss                                                             0.99821\n",
       "acc                                                             0.492524\n",
       "precision                                                       0.586298\n",
       "recall                                                          0.212996\n",
       "f1score                                                         0.303709\n",
       "val_loss                                                        0.942541\n",
       "val_acc                                                         0.537287\n",
       "val_precision                                                   0.642103\n",
       "val_recall                                                      0.310014\n",
       "val_f1score                                                     0.417802\n",
       "Name: 62, Length: 21, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the best paramaters\n",
    "gs_results.iloc[i_best, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retraining with the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 6s - loss: 1.0057 - accuracy: 0.4904 - val_loss: 0.9494 - val_accuracy: 0.5281\n"
     ]
    }
   ],
   "source": [
    "### Build a simple LSTM that has 64 hidden units \n",
    "p = {'max_len': 10,\n",
    "     'embedding_input': None,\n",
    "     'embedding_dim': None,\n",
    "     'epochs': 1, # number of iterations on the full set \n",
    "     'batch_size': 256, \n",
    "     'hidden_neuron': 32, # number of neurons in the input layer \n",
    "     'lr': 0.01, # learning rate       \n",
    "     'dropout': 0.1, \n",
    "     'optimizer': RMSprop, \n",
    "     'losses': categorical_crossentropy, \n",
    "     'last_activation': 'softmax'}\n",
    "\n",
    "# Model fitting\n",
    "LSTM_hist, LSTM_model = md.train(model = 'LSTM', \n",
    "                                               data_train = tenses_train, \n",
    "                                               data_valid = tenses_valid, \n",
    "                                               cue_index = cue_to_index, \n",
    "                                               outcome_index = outcome_to_index, \n",
    "                                               verbose = 2,\n",
    "                                               metrics = ['accuracy'],\n",
    "                                               params = p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and training history\n",
    "MODEL_PATH = TOP + 'illustrative_examples/tenses/Results/LSTM_tenses.h5'\n",
    "HISTORY_PATH = TOP + 'illustrative_examples/tenses/Results/LSTM_history_dict_tenses'\n",
    "md.export_model(model = LSTM_model, path = MODEL_PATH)  # creates a HDF5 file \n",
    "md.export_history(history_dict = LSTM_hist, path = HISTORY_PATH)\n",
    "del LSTM_model, LSTM_hist  # deletes the existing model and history dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and training history\n",
    "MODEL_PATH = TOP + 'illustrative_examples/tenses/Results/LSTM_tenses.h5'\n",
    "HISTORY_PATH = TOP + 'illustrative_examples/tenses/Results/LSTM_history_dict_tenses'\n",
    "LSTM_model = md.import_model(MODEL_PATH)\n",
    "LSTM_history_dict = md.import_history(path = HISTORY_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FutureSimple': 0.8418307, 'PastSimple': 0.034237638, 'PresentSimple': 0.12393176}\n"
     ]
    }
   ],
   "source": [
    "# Test prediction for a single given cue sequence. Model expect inout as array of shape (1, N_cues) \n",
    "cue1_seq = 'I_you_tomorrow' # context from the sentence 'I will meet you tomorrow'\n",
    "outcome1_prob_pred = ev.predict_proba_oneevent_LSTM(model = LSTM_model, \n",
    "                                                   cue_seq = cue1_seq, \n",
    "                                                   cue_index = cue_to_index,\n",
    "                                                   max_len = 10,\n",
    "                                                   vector_encoding = 'onehot')\n",
    "print({index_to_outcome[j+1]:outcome1_prob_pred[j] for j in range(len(outcome1_prob_pred))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "prob_pred = ev.predict_proba_eventfile_LSTM(model = LSTM_model, \n",
    "                                           data_test = tenses_test, \n",
    "                                           cue_index = cue_to_index, \n",
    "                                           outcome_index = outcome_to_index, \n",
    "                                           max_len = 10,  \n",
    "                                           vector_encoding = 'onehot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5263333333333333"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# True responses to compare the predictions to\n",
    "y_test = tenses_test.replace({'outcomes': outcome_to_index})['outcomes']\n",
    "y_pred = np.argmax(prob_pred, axis=1)+1\n",
    "\n",
    "# Overall test accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FutureSimple': 0.6788899900891973, 'PastSimple': 0.4709480122324159, 'PresentSimple': 0.4277227722772277}\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy per class\n",
    "cmat = confusion_matrix(y_test, y_pred, labels = list(outcome_to_index.values())) # Confusion matrix\n",
    "cmat_diag = cmat.diagonal()/cmat.sum(axis=1)\n",
    "print({index_to_outcome[j+1]:cmat_diag[j] for j in range(len(cmat_diag))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Naive discriminative learning model <a ID=\"V\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a simple NDL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 81s - acc: 0.5170 - val_acc: 0.5047\n",
      "Epoch 2/10\n",
      " - 81s - acc: 0.5375 - val_acc: 0.5131\n",
      "Epoch 3/10\n",
      " - 82s - acc: 0.5480 - val_acc: 0.5255\n",
      "Epoch 4/10\n",
      " - 82s - acc: 0.5571 - val_acc: 0.5315\n",
      "Epoch 5/10\n",
      " - 83s - acc: 0.5613 - val_acc: 0.5332\n",
      "Epoch 6/10\n",
      " - 82s - acc: 0.5667 - val_acc: 0.5322\n",
      "Epoch 7/10\n",
      " - 81s - acc: 0.5715 - val_acc: 0.5301\n",
      "Epoch 8/10\n",
      " - 80s - acc: 0.5751 - val_acc: 0.5311\n",
      "Epoch 9/10\n",
      " - 79s - acc: 0.5771 - val_acc: 0.5311\n",
      "Epoch 10/10\n",
      " - 79s - acc: 0.5794 - val_acc: 0.5338\n"
     ]
    }
   ],
   "source": [
    "### Build a simple NDL\n",
    "p = {'epochs': 10, # number of iterations on the full set \n",
    "    'lr': 0.001}\n",
    "\n",
    "# Model fitting\n",
    "NDL_history_dict, NDL_model = md.train(model = 'NDL',\n",
    "                                       data_train = tenses_train, \n",
    "                                       data_valid = tenses_valid,  \n",
    "                                       cue_index = cue_to_index, \n",
    "                                       outcome_index = outcome_to_index, \n",
    "                                       num_threads = 16, \n",
    "                                       verbose = 1,\n",
    "                                       params = p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate learning curve\n",
    "ev.plot_learning_curve(history_dict = NDL_history_dict, metric = 'accuracy', set = 'train_valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune the parameters to find a good model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 out of 8: {'lr': 0.005, 'epochs': 2}\n",
      "\n",
      "Iteration 2 out of 8: {'lr': 0.0005, 'epochs': 8}\n",
      "\n",
      "Iteration 3 out of 8: {'lr': 0.05, 'epochs': 6}\n",
      "\n",
      "Iteration 4 out of 8: {'lr': 5e-05, 'epochs': 6}\n",
      "\n",
      "Iteration 5 out of 8: {'lr': 5e-05, 'epochs': 2}\n",
      "\n",
      "This parameter combination has already been processed: {'lr': 5e-05, 'epochs': 2}\n",
      "\n",
      "Iteration 6 out of 8: {'lr': 1e-05, 'epochs': 6}\n",
      "\n",
      "Iteration 7 out of 8: {'lr': 0.01, 'epochs': 8}\n",
      "\n",
      "Iteration 8 out of 8: {'lr': 5e-05, 'epochs': 1}\n",
      "\n",
      "This parameter combination has already been processed: {'lr': 5e-05, 'epochs': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Parameter tuning using grid search \n",
    "p = {'lr': [0.00001, 0.00005, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05], # learning rate (x8)\n",
    "     'epochs': [1, 2, 4, 6, 8], # number of iterations on the full set (x5)\n",
    "     }\n",
    "# => Total number of combinations: 8*5 = 40\n",
    "\n",
    "### Grid search \n",
    "TUNING_PATH = TOP + 'illustrative_examples/tenses/Results/grid_search_NDL_tenses.csv'\n",
    "md.grid_search_NDL(data_train = tenses_train, \n",
    "                   data_valid = tenses_valid, \n",
    "                   cue_index = cue_to_index, \n",
    "                   outcome_index = outcome_to_index, \n",
    "                   params = p, \n",
    "                   prop_grid = 0.2, \n",
    "                   shuffle_grid = True,\n",
    "                   tuning_output_file = TUNING_PATH, \n",
    "                   num_threads = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the grid search file to analyse the results \n",
    "gs_results = pd.read_csv(TUNING_PATH, index_col = False)\n",
    "\n",
    "# get the number of parameter combinations that were processed\n",
    "len(gs_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>epochs</th>\n",
       "      <th>acc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1score</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>val_f1score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0050</td>\n",
       "      <td>1</td>\n",
       "      <td>0.555034</td>\n",
       "      <td>0.553968</td>\n",
       "      <td>0.554828</td>\n",
       "      <td>0.552948</td>\n",
       "      <td>0.522773</td>\n",
       "      <td>0.520583</td>\n",
       "      <td>0.523438</td>\n",
       "      <td>0.520869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0050</td>\n",
       "      <td>2</td>\n",
       "      <td>0.573547</td>\n",
       "      <td>0.572125</td>\n",
       "      <td>0.573428</td>\n",
       "      <td>0.572314</td>\n",
       "      <td>0.526457</td>\n",
       "      <td>0.524693</td>\n",
       "      <td>0.527256</td>\n",
       "      <td>0.525527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>1</td>\n",
       "      <td>0.498408</td>\n",
       "      <td>0.503528</td>\n",
       "      <td>0.497742</td>\n",
       "      <td>0.482053</td>\n",
       "      <td>0.490623</td>\n",
       "      <td>0.492990</td>\n",
       "      <td>0.491281</td>\n",
       "      <td>0.474983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>2</td>\n",
       "      <td>0.516418</td>\n",
       "      <td>0.517535</td>\n",
       "      <td>0.515942</td>\n",
       "      <td>0.506346</td>\n",
       "      <td>0.503684</td>\n",
       "      <td>0.503838</td>\n",
       "      <td>0.504498</td>\n",
       "      <td>0.494179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>3</td>\n",
       "      <td>0.528564</td>\n",
       "      <td>0.528750</td>\n",
       "      <td>0.528171</td>\n",
       "      <td>0.521550</td>\n",
       "      <td>0.513396</td>\n",
       "      <td>0.511864</td>\n",
       "      <td>0.514202</td>\n",
       "      <td>0.506442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lr  epochs       acc  precision    recall   f1score   val_acc  \\\n",
       "0  0.0050       1  0.555034   0.553968  0.554828  0.552948  0.522773   \n",
       "1  0.0050       2  0.573547   0.572125  0.573428  0.572314  0.526457   \n",
       "2  0.0005       1  0.498408   0.503528  0.497742  0.482053  0.490623   \n",
       "3  0.0005       2  0.516418   0.517535  0.515942  0.506346  0.503684   \n",
       "4  0.0005       3  0.528564   0.528750  0.528171  0.521550  0.513396   \n",
       "\n",
       "   val_precision  val_recall  val_f1score  \n",
       "0       0.520583    0.523438     0.520869  \n",
       "1       0.524693    0.527256     0.525527  \n",
       "2       0.492990    0.491281     0.474983  \n",
       "3       0.503838    0.504498     0.494179  \n",
       "4       0.511864    0.514202     0.506442  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the dataframe containing the tuning results\n",
    "gs_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Highest validation accuracy: 0.5331547220361688\n",
      "- Highest validation f1-score: 0.5956459106368405\n"
     ]
    }
   ],
   "source": [
    "# get the highest result for any metric\n",
    "print(f\"- Highest validation accuracy: {gs_results['val_acc'].max()}\")\n",
    "print(f\"- Highest validation f1-score: {gs_results['f1score'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the index of the combination with the best result\n",
    "i_best = gs_results['val_acc'].argmax()\n",
    "i_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lr               0.000500\n",
       "epochs           8.000000\n",
       "acc              0.556752\n",
       "precision        0.555440\n",
       "recall           0.556527\n",
       "f1score          0.553571\n",
       "val_acc          0.533155\n",
       "val_precision    0.531244\n",
       "val_recall       0.533971\n",
       "val_f1score      0.529704\n",
       "Name: 9, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the best paramaters\n",
    "gs_results.iloc[i_best, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retraining with the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      " - 81s - acc: 0.4984 - val_acc: 0.4906\n",
      "Epoch 2/8\n",
      " - 81s - acc: 0.5164 - val_acc: 0.5037\n",
      "Epoch 3/8\n",
      " - 81s - acc: 0.5286 - val_acc: 0.5134\n",
      "Epoch 4/8\n",
      " - 81s - acc: 0.5367 - val_acc: 0.5161\n",
      "Epoch 5/8\n",
      " - 82s - acc: 0.5442 - val_acc: 0.5201\n",
      "Epoch 6/8\n",
      " - 79s - acc: 0.5486 - val_acc: 0.5248\n",
      "Epoch 7/8\n",
      " - 79s - acc: 0.5534 - val_acc: 0.5308\n",
      "Epoch 8/8\n",
      " - 78s - acc: 0.5568 - val_acc: 0.5332\n"
     ]
    }
   ],
   "source": [
    "### Hyperparameters to use\n",
    "p = {'epochs': 8, # number of iterations on the full set \n",
    "    'lr': 0.0005}\n",
    "\n",
    "# Model fitting\n",
    "NDL_hist, NDL_model = md.train(model = 'NDL',\n",
    "                               data_train = tenses_train, \n",
    "                               data_valid = tenses_valid,  \n",
    "                               cue_index = cue_to_index, \n",
    "                               outcome_index = outcome_to_index, \n",
    "                               num_threads = 16, \n",
    "                               verbose = 1,\n",
    "                               params = p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights and training history\n",
    "MODEL_PATH = TOP + 'illustrative_examples/tenses/Results/NDL_tenses.h5'\n",
    "HISTORY_PATH = TOP + 'illustrative_examples/tenses/Results/NDL_history_dict_tenses'\n",
    "md.export_model(model = NDL_model, path = MODEL_PATH)  # create a HDF5 file \n",
    "md.export_history(history_dict = NDL_hist, path = HISTORY_PATH)\n",
    "del NDL_model, NDL_history_dict  # delete the existing model and history dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and training history\n",
    "MODEL_PATH = TOP + 'illustrative_examples/tenses/Results/NDL_tenses.h5'\n",
    "HISTORY_PATH = TOP + 'illustrative_examples/tenses/Results/NDL_history_dict_tenses'\n",
    "NDL_model = md.import_model(MODEL_PATH)\n",
    "NDL_history_dict = md.import_history(path = HISTORY_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41608894 0.32474414 0.25916692]\n",
      "{'FutureSimple': 0.4160889379720033, 'PastSimple': 0.3247441402929446, 'PresentSimple': 0.25916692173505207}\n"
     ]
    }
   ],
   "source": [
    "# Test prediction for a single given cue sequence. Model expect input as array of shape (1, N_cues) \n",
    "cue1_seq = 'I_you_tomorrow' # context from the sentence 'I will meet you tomorrow'\n",
    "outcome1_prob_pred = ev.predict_proba_oneevent_NDL(model = NDL_model, \n",
    "                                                   cue_seq = cue1_seq)\n",
    "print(outcome1_prob_pred) # vector of predicted probabilities\n",
    "print({index_to_outcome[j+1]:outcome1_prob_pred[j] for j in range(len(outcome1_prob_pred))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability of future seems low, not because the model is unconfident, but because the softmax transformation used is 'soft' in terms of converting activations to probabilities. Decreasing the temperature parameter can emphasise more the predictions bewteen the three tense: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91520762 0.07674872 0.00804366]\n",
      "{'FutureSimple': 0.9152076178518962, 'PastSimple': 0.0767487235123707, 'PresentSimple': 0.008043658635733074}\n"
     ]
    }
   ],
   "source": [
    "# Test prediction for a single given cue sequence. Model expect input as array of shape (1, N_cues) \n",
    "cue1_seq = 'I_will_meet_you_tomorrow'\n",
    "outcome1_prob_pred = ev.predict_proba_oneevent_NDL(model = NDL_model, \n",
    "                                                   cue_seq = cue1_seq,\n",
    "                                                   T = 0.1)\n",
    "print(outcome1_prob_pred) # vector of predicted probabilities\n",
    "print({index_to_outcome[j+1]:outcome1_prob_pred[j] for j in range(len(outcome1_prob_pred))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5306666666666666"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Evaluate the model on the test set\n",
    "# True outcomes to compare the predictions to\n",
    "y_test = tenses_test['outcomes'].tolist()\n",
    "\n",
    "# Predicted outcomes\n",
    "y_pred = ev.predict_outcomes_NDL(model = NDL_model, \n",
    "                                 data_test = tenses_test,\n",
    "                                 num_threads = 16)\n",
    "\n",
    "# Overall test accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FutureSimple': 0.605759682224429, 'PastSimple': 0.5927835051546392, 'PresentSimple': 0.40336967294350845}\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy per class\n",
    "cmat = confusion_matrix(y_test, y_pred, labels = list(outcome_to_index.keys())) # Confusion matrix\n",
    "cmat_diag = cmat.diagonal()/cmat.sum(axis=1)\n",
    "print({index_to_outcome[j+1]:cmat_diag[j] for j in range(len(cmat_diag))})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
